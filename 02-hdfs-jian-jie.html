<!DOCTYPE html>
<html lang="zh">
  <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <title>02. HDFS 简介</title>
    <link
      rel="icon"
      href="http://uldaman.github.io/old_pages/extra/avatar.png"
    />
    <link
      rel="shortcut icon"
      href="http://uldaman.github.io/old_pages/extra/avatar.png"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"
    />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.5/css/bulma.min.css"
    />
    <link
      rel="stylesheet"
      href="http://uldaman.github.io/old_pages/theme/css/main.a3671138.css"
    />
    <style media="print">
      .is-hidden-print {
        display: none !important;
      }
    </style>
    <link
      rel="stylesheet"
      href="http://uldaman.github.io/old_pages/custom.css"
    />
    <meta property="og:title" content="Small Cpp - 02. HDFS 简介" />
    <meta property="og:description" content="HDFS 简介" />
    <meta
      property="og:url"
      content="http://uldaman.github.io/old_pages/02-hdfs-jian-jie.html"
    />
    <meta property="og:image" content="http://i61.tinypic.com/dwcpw9.jpg" />
    <meta
      name="twitter:image:alt"
      content="Small Cpp | 勿在浮沙筑高台, 练从难处练, 用从易处用."
    />
    <meta name="twitter:card" content="summary" />
    <meta property="og:site_name" content="Small Cpp" />
    <meta property="og:type" content="article" />
    <meta
      property="article:published_time"
      content="2016-10-20T20:52:00+08:00"
    />
    <meta property="article:section" content="大数据" />
  </head>

  <body id="index" class="home">
    <header class="hero is-primary">
      <div class="hero-head">
        <div class="container">
          <nav class="navbar">
            <div class="navbar-brand">
              <a
                class="navbar-item title is-3"
                href="http://uldaman.github.io/old_pages/"
                ><img
                  src="http://uldaman.github.io/old_pages/extra/avatar.png"
                  class="avatar"
                />&nbsp;Small Cpp</a
              >
            </div>
          </nav>
        </div>
      </div>
    </header>

    <nav class="navbar has-shadow is-hidden-print">
      <div class="container">
        <div class="navbar-center"></div>
        <span id="navToggle" class="navbar-burger">
          <span></span>
          <span></span>
          <span></span>
        </span>
        <div id="navMenu" class="navbar-menu">
          <div class="navbar-end">
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/za-xiang.html"
              >杂项</a
            >
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/shu-ju-ku.html"
              >数据库</a
            >
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/ruan-jian-gong-cheng.html"
              >软件工程</a
            >
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/han-shu-shi.html"
              >函数式</a
            >
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/gong-ju-zhe-teng.html"
              >工具折腾</a
            >
            <a
              class="navbar-item is-tab"
              href="http://uldaman.github.io/old_pages/category/golang.html"
              >Golang</a
            >
            <a
              class="navbar-item is-tab is-active"
              href="http://uldaman.github.io/old_pages/category/da-shu-ju.html"
              >大数据</a
            >
          </div>
        </div>
      </div>
    </nav>

    <div class="container">
      <div class="section columns">
        <div class="column is-three-quarters-desktop is-two-thirds-tablet">
          <section id="content" class="body">
            <article>
              <h1 class="title">
                <a
                  href="http://uldaman.github.io/old_pages/02-hdfs-jian-jie.html"
                  rel="bookmark"
                  title="Permalink to 02. HDFS 简介"
                  >02. HDFS 简介</a
                >
              </h1>
              <footer class="post-info">
                <abbr class="published" title="2016-10-20T20:52:00+08:00">
                  Published <span class="is-info">Thu 20 October 2016</span> in
                  <a
                    href="http://uldaman.github.io/old_pages/category/da-shu-ju.html"
                    >大数据</a
                  >
                </abbr>

                <p class="author">
                  <em>by HanXiao </em>
                  &nbsp;
                </p>
              </footer>
              <div class="section">
                <div class="toc">
                  <ul>
                    <li><a href="#_1">分布式文件系统</a></li>
                    <li><a href="#hdfs">HDFS 的可靠性</a></li>
                    <li>
                      <a href="#_2">体系结构</a>
                      <ul>
                        <li><a href="#namenode">NameNode</a></li>
                        <li>
                          <a href="#secondary-namenode">Secondary NameNode</a>
                        </li>
                        <li><a href="#datanode">DataNode</a></li>
                        <li>
                          <a href="#block">读取数据流程 (以 block 为单位)</a>
                        </li>
                        <li>
                          <a href="#block_1">写入数据流程 (以 block 为单位)</a>
                        </li>
                      </ul>
                    </li>
                  </ul>
                </div>
                <hr />

                <h1 id="_1">分布式文件系统</h1>
                <p>
                  HDFS 是一种分布式文件系统, 即 Hadoop Distributed File System
                  (Hadoop 的分布式文件系统).
                </p>
                <p>
                  常见的分布式文件系统有, GFS、HDFS、Lustre 、Ceph 、GridFS
                  、mogileFS、TFS、FastDFS等; 各自适用于不同的领域,
                  它们都不是系统级的分布式文件系统,
                  而是应用级的分布式文件存储服务.
                </p>
                <p><strong>什么是分布式文件系统?</strong></p>
                <p>
                  数据量越来越多, 在一个操作系统管辖的范围存不下了,
                  那么就分配到更多的操作系统管理的磁盘中, 但是不方便管理和维护,
                  因此迫切需要一种系统来管理多台机器上的文件,
                  这就是分布式文件管理系统.
                </p>
                <p>
                  它是一种允许文件通过<strong>网络</strong>在多台主机上<strong>分享</strong>的文件系统,
                  可让多机器上的多用户分享文件和存储空间,
                  为进一步的大数据<strong>分析</strong>提供数据支持.
                </p>
                <p>
                  <strong>通透性</strong>: 让实际上是通过网络来访问文件的动作,
                  由程序与用户看来, 就像是访问本地的磁盘一般
                  (对比下共享文件的方式, 需要知道对方的 ip 地址才能访问).
                </p>
                <p>
                  <strong>容错</strong>: 自动数据冗余, 即使系统中有某些节点脱机,
                  整体来说系统仍然可以持续运作而不会有数据损失; 功能类似 Raid
                  自动备份功能, 在 <code>hdfs-site.xml</code> 文件中会配置个
                  <code>dfs.replication</code> 参数用来指定 Hadoop
                  集群的复制因子 (也就是一个文件会备份几份).
                </p>
                <p>
                  分布式文件管理系统很多, HDFS 只是其中一种; 它是流式的数据访问,
                  也就是说批量读取而非随机读取, 所以它擅长的是
                  <strong>OLAP</strong>, 而不是 <strong>OLTP</strong>,
                  适用于<strong>一次写入多次查询</strong>的情况,
                  <strong>不支持</strong>并发写情况,
                  <strong>不合适</strong>存储小文件.
                </p>
                <p>
                  <strong>一次写入</strong>即写入后无法更新, 只能删除重写, 2.0
                  好像支持追加内容.
                </p>
                <p>
                  <strong>不支持并发写</strong>并不是指不能同时存储多份文件,
                  而是指, 一份大文件被分成多个块时, 是一个块写满再写另一个块的,
                  不能同时写所有的块.
                </p>
                <p>
                  <strong>不合适存储小文件</strong>, 因为 NameNode
                  将文件系统中的元数据存储在内存中, 因此, HDFS
                  所能存储的文件数量会受到 NameNode 内存的限制.
                </p>
                <p>下面是一张 HDFS 的简单示图, 参考下:</p>
                <p>
                  <img alt="HDFS" src="http://i61.tinypic.com/dwcpw9.jpg" />
                </p>
                <p>
                  当 <strong>Client</strong> 需要存储一份文件的时候, 如 a.log
                  (200M), Client 先和 HDFS 中的
                  <strong>NameNode</strong> 取得联系, NameNode
                  从自己的集群中找到一个可以存储的
                  <strong>DataNode</strong> 并告诉 Client, Client 开始向指定的
                  DataNode 存储数据.<br />
                  存储数据的时候, 会根据文件的大小分块存储(2.0 默认 128M),
                  当存储完一个块后, DataNode 会检查 NameNode 中设置的副本数量,
                  如果不止一份的话, 当前 DataNode 就会水平传递 (pipline)
                  块给其他的 DataNode, 然后再申请另一个块,
                  继续存储剩余的文件内容…以此类推.
                </p>
                <h1 id="hdfs">HDFS 的可靠性</h1>
                <ul>
                  <li>
                    <strong>冗余副本策略</strong> + 数据会根据复制因子保存多份,
                    即使系统中有某些节点脱机,
                    整体来说系统仍然可以持续运作而不会有数据损失
                  </li>
                  <li>
                    <strong>机架感知</strong> + 集群一般放在不同机架上,
                    副本保存在不同的机架上, 这样可以防止机架故障时丢失数据
                  </li>
                  <li>
                    <strong>心跳机制</strong> + NameNode 周期性从 DataNode
                    接收心跳信号和块报告 (blockport) 以验证 DataNode
                    是否宕掉及数据块是否正常
                  </li>
                  <li>
                    <strong>安全模式</strong> + 当集群的 DataNode
                    不满足复制因子数据时, 集群进入安全模式, 不允许使用
                  </li>
                  <li>
                    <strong>校验和</strong> + 在 DataNode 中, 除了保存数据块外,
                    还保存一份数据块的 <code>.mete</code> 文件,
                    该文件保存正常情况下数据块的校验和, DataNode
                    通过验证当前数据块的校验和与
                    <code>.mete</code> 中的是否相等来判断数据块是否正常
                  </li>
                  <li>
                    <strong>回收站</strong> + 该功能默认关闭, 开启时, 当 HDFS
                    删除数据时, 不是直接删除, 而是放到回收站中, 避免误删
                  </li>
                  <li>
                    <strong>元数据保护</strong> + 即 NameNode
                    中的元数据也可以配置成保存多份
                  </li>
                  <li>
                    <strong>快照机制</strong> + 支持存储某个时间点的映像,
                    需要时, 可以使数据重迒返个时间点的状态
                  </li>
                </ul>
                <h1 id="_2">体系结构</h1>
                <ul>
                  <li>NameNode + 事务日志 + 映像文件</li>
                  <li>SecondaryNameNode</li>
                  <li>DataNode</li>
                </ul>
                <h2 id="namenode">NameNode</h2>
                <p>
                  NameNode 是管理节点, 维护集群的<a
                    href="http://wiki.smallcpp.com/Hadoop/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E8%A7%A3%E6%9E%90.html"
                    >命名空间</a
                  >
                  (就是集群 HDFS 的目录结构),
                  包括文件目录树、文件/目录的元数据、每个文件对应的数据块列表,
                  以及接收用户的操作请求.
                </p>
                <p><strong>MetaData</strong> (元数据)</p>
                <p>
                  存储细节: 为了性能和安全兼具, Metadata 在 HDFS
                  中会存储<strong>两</strong>份, 内存一份, 磁盘一份(镜像).
                </p>
                <table>
                  <thead>
                    <tr>
                      <th><code>/test/a.log</code></th>
                      <th>3</th>
                      <th><code>{blk_1, blk_2}</code></th>
                      <th>
                        <code
                          >[{blk_1: [h0, h1, h3]}, {blk_2: [h0, h2, h4]}]</code
                        >
                      </th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>文件名</td>
                      <td>副本数</td>
                      <td>文件被分多少块</td>
                      <td>每个块分别被保存在哪个 DataNode 上</td>
                    </tr>
                  </tbody>
                </table>
                <p>HDFS 通过 CRC 校验块的完整性.</p>
                <p>
                  Namenode 使用<strong>事务日志</strong>记录 HDFS 元数据的变化,
                  使用<strong>映像文件</strong>存储 MetaData.
                </p>
                <p>
                  事务日志和映像文件保存在
                  <code>/tmp/dfs/name/current</code> 目录下:
                </p>
                <ul>
                  <li>
                    <strong>fsimage</strong>: 元数据镜像文件, 存储某一时候
                    NameNode 的内存元数据信息
                  </li>
                  <li><strong>edits</strong>: 操作日志文件</li>
                  <li>
                    <strong>fstime</strong>: 保存最近一次 checkpoint 的时间
                    (还原点)
                  </li>
                </ul>
                <p>
                  当有操作发生时, NameNode 首先向写操作日志到磁盘, 即向
                  <strong>edits</strong> 文件中写日志, 成功返回后, 才会修改内存,
                  并且向客户端返回.
                </p>
                <p>
                  Hadoop 会维护一个 <strong>fsimage</strong> 文件, 也就是
                  NameNode 中 MetaData 的硬盘镜像, 但是
                  <strong>fsimage</strong> 不会随时与 NameNode 内存中的 MetaData
                  保持一致, 而是每隔一段时间通过合并
                  <strong>edits</strong> 文件来更新内容 (仅限 1.0 和 伪分布式,
                  2.0 集群是实时的),
                  <strong>edits</strong> 合并后就会进行一次清空. Secondary
                  NameNode 就是用来合并 <strong>fsimage</strong> 和
                  <strong>edits</strong> 文件来更新 NameNode 的 MetaData 的.
                </p>
                <p>
                  在 <code>/tmp/dfs/name/current</code> 目录下,
                  除了那三个文件外, 还有个 <strong>VERSION</strong> 文件:
                </p>
                <div class="codehilite" style="background: #eeeedd">
                  <pre
                    style="line-height: 125%"
                  ><span></span>hanxiao@smallcpp01:/usr/smallcpp/hadoop-2.7.3/tmp/dfs/name/current$ cat VERSION
<span style="color: #228B22">#Sun Oct 16 17:28:41 CST 2016</span>
<span style="color: #00688B">namespaceID</span>=<span style="color: #B452CD">1526300018</span>
<span style="color: #00688B">clusterID</span>=CID-cc6f47f9-4021-4f9b-87a6-ad7ad82b7af7
<span style="color: #00688B">cTime</span>=<span style="color: #B452CD">0</span>
<span style="color: #00688B">storageType</span>=NAME_NODE
<span style="color: #00688B">blockpoolID</span>=BP-1803451175-192.168.142.155-1476610121875
<span style="color: #00688B">layoutVersion</span>=-63
</pre>
                </div>
                <p>这里的数据是用来标识集群、节点唯一性的.</p>
                <h2 id="secondary-namenode">Secondary NameNode</h2>
                <p>
                  Secondary NameNode 的作用主要体现在 Hadoop 1.x 下, Secondary
                  NameNode 会按照配置的时间及大小定期合并 NameNode 节点上的
                  fsimage 和 edits, 这样做的目的包含三方面:
                </p>
                <ul>
                  <li>
                    edits 中可能包含一些文件的创建及删除的操作, 合并之后,
                    删除的文件就不存在了, 只保存了存在的文件,
                    删除的文件也就不会合并到 fsimage 中, 这样会节省空间
                  </li>
                  <li>
                    NameNode 在每次重启时都会将 fsimage 和 edits 合并, 如果不在
                    Secondary NameNode 中定期合并, 在重启 NameNode 时会非常慢
                  </li>
                  <li>提供冷备份的功能</li>
                </ul>
                <p>
                  在 Hadoop 2.X 中, 提供了 HA 解决方案 (高可用), 彻底解决了
                  NameNode 单点的问题, 也就不存在 Secondary NameNode, 引入了
                  Standby NameNode,可以顺利的将 Active NameNode 进行热备.
                </p>
                <p><strong>工作模式</strong>:</p>
                <p>
                  从 NameNode 下载元数据信息 (<strong>fsimage</strong>,
                  <strong>edits</strong>), 然后合并二者, 生成新的
                  <strong>fsimage</strong>, 在本地保存一份后推送到 NameNode,
                  替换旧的 <strong>fsimage</strong>.
                </p>
                <p>
                  <img
                    alt=""
                    src="http://uldaman.github.io/old_pages/images/Hdfs简介/SecondaryNameNode.jpg"
                  />
                </p>
                <p><strong>什么时候同步?</strong></p>
                <ul>
                  <li>
                    <code>fs.checkpoint.period</code> 指定两次 checkpoint
                    的最大时间间隔, 默认 3600 秒
                  </li>
                  <li>
                    <code>fs.checkpoint.size</code> 规定 edits 的大小, 默认 64M
                  </li>
                </ul>
                <h2 id="datanode">DataNode</h2>
                <p>真实文件数据存储服务</p>
                <p>
                  文件块(block): 最基本存储单位, hp 1.0 默认 64M, hp 2.0 默认
                  128M, 从文件的 0 编号开始, 按指定大小,
                  顺序对文件进行划分并编号.
                </p>
                <p>
                  HDFS 中, 如果一个文件小于一个数据块的大小 , 并不占用整个数据块
                  (这些文件最终被保存在 tmp/dfs/data/current/…/finalized/ 中).
                </p>
                <p>
                  默认 3 个副本 (如果已存在一份存储好的文件(3个副本),
                  突然有一个小弟挂掉了, NameNode
                  会再安排另一个小弟重新备份这个文件, 这是基于心跳包机制的).
                </p>
                <h2 id="block">读取数据流程 (以 block 为单位)</h2>
                <ul>
                  <li>客户端要访问 HDFS 中的一个文件</li>
                  <li>首先从 NameNode 获得组成返个文件的数据块位置列表</li>
                  <li>根据列表知道存储数据块的 DataNode</li>
                  <li>访问 DataNode 获取数据</li>
                  <li>NameNode 并不参不数据实际传输</li>
                </ul>
                <h2 id="block_1">写入数据流程 (以 block 为单位)</h2>
                <p>
                  HDFS client 上传数据到 HDFS 时,
                  会首先在本地<strong>缓存</strong>数据, 当数据达到一个 block
                  大小时, 请求 NameNode 分配一个 block. NameNode
                  就会从当前集群寻找一个空闲 block, 然后把 block 所在的 DataNode
                  的信息告诉 HDFS client. HDFS client 拿到信息后直接和 DataNode
                  通信, 把数据写到 DataNode 节点的一个 block 文件中
                  (在传输过程中, 以 Packet 为最小单位).
                </p>
                <p>
                  由于 Hadoop 有副本机制, 例如三个, 所以 NameNode 会寻找三个空闲
                  block 组成 pipeline, 依次将目标数据块写入各个 DataNode,
                  建立多个副本, 待所以副本数据都上传完毕后, HDFS client
                  会继续下一个 block 的操作.
                </p>
                <p>
                  <img
                    alt=""
                    src="http://uldaman.github.io/old_pages/images/Hdfs简介/hdfswriteflow.png"
                  />
                </p>
              </div>
            </article>
          </section>

          <script type="application/ld+json">
            {
              "articleSection": "\u5927\u6570\u636e",
              "author": { "@type": "Person", "name": "HanXiao" },
              "datePublished": "2016-10-20T20:52:00+08:00",
              "headline": "02. HDFS \u7b80\u4ecb",
              "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "http://uldaman.github.io/old_pages/02-hdfs-jian-jie.html"
              },
              "@context": "http://schema.org",
              "@type": "BlogPosting",
              "description": "HDFS \u7b80\u4ecb",
              "image": {
                "@type": "ImageObject",
                "url": "http://i61.tinypic.com/dwcpw9.jpg"
              }
            }
          </script>
        </div>

        <div
          class="column is-one-quarter-desktop is-one-third-tablet is-hidden-print"
        >
          <aside class="menu">
            <p class="menu-label">Links</p>
            <ul class="menu-list">
              <li>
                <a href="https://zhuec.gitbook.io/learning-notes/">
                  <span class="icon is-small"
                    ><i class="fa fa-globe fa-fw"></i
                  ></span>
                  <span class="link-text">Learning Notes</span>
                </a>
              </li>
              <li>
                <a href="https://github.com/vechain/thor">
                  <span class="icon is-small"
                    ><i class="fa fa-globe fa-fw"></i
                  ></span>
                  <span class="link-text">VeChain Thor</span>
                </a>
              </li>
              <li>
                <a href="http://blog.csdn.net/u010850265">
                  <span class="icon is-small"
                    ><i class="fa fa-globe fa-fw"></i
                  ></span>
                  <span class="link-text">CSDN</span>
                </a>
              </li>
            </ul>
          </aside>
        </div>
      </div>
    </div>

    <footer class="footer">
      <div class="container has-text-centered">
        <p class="subtitle">勿在浮沙筑高台, 练从难处练, 用从易处用.</p>
        <div class="credits">
          <span
            ><a href="https://github.com/textbook/bulrush">Bulrush</a> theme for
            <a href="https://blog.getpelican.com/">Pelican</a></span
          >
          <span
            ><span class="icon is-small"><i class="fa fa-html5"></i></span> HTML
            5</span
          >
          <span
            ><span class="icon is-small"><i class="fa fa-css3"></i></span> CSS
            3</span
          >
          <span>Made with <a href="https://bulma.io">Bulma</a></span>
        </div>
      </div>
      <div class="github-fork-ribbon-wrapper is-hidden-mobile is-hidden-print">
        <div class="github-fork-ribbon">
          <a href="https://github.com/uldaman">
            <i class="fa fa-github fa-fw"></i>
            Fork me on GitHub
          </a>
        </div>
      </div>
    </footer>

    <script type="text/javascript">
      document
        .getElementById("navToggle")
        .addEventListener("click", function () {
          var nav = document.getElementById("navMenu");
          var className = nav.getAttribute("class");
          if (className == "navbar-menu") {
            nav.className = "navbar-menu is-active";
          } else {
            nav.className = "navbar-menu";
          }
        });
    </script>
  </body>
</html>
